{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish importing packages\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and packages for the project \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "\n",
    "print('- Finish importing packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congtu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish initializing a driver\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Login to batdongsan.com\n",
    "\n",
    "# Task 1.1: Open Chrome\n",
    "driver = webdriver.Chrome(\"/home/congtu/Documents/Hoc/XuLyDuLieuLon/BTL/Crawl_data/chromedriver\")\n",
    "driver.set_window_size(1920,1080)\n",
    "sleep(2)\n",
    "url = 'https://batdongsan.com.vn/ban-can-ho-chung-cu'\n",
    "driver.get(url)\n",
    "print('- Finish initializing a driver')\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages you want to scrape: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congtu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish Task 3: Scrape the URLs\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Scrape the URLs\n",
    "# Task 2.1: Write a function to extract the URLs of one page\n",
    "def GetURL():\n",
    "    page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    profiles = page_source.find_all('a', class_ = 'js__product-link-for-product-id') #('a', class_ = 'search-result__result-link ember-view')\n",
    "    all_profile_URL = []\n",
    "    for profile in profiles:\n",
    "        # profile_ID = profile.get('href')\n",
    "        profile_URL = \"https://batdongsan.com.vn\" + profile.get('href')\n",
    "        # profile_URL = profile.get('href')\n",
    "        if profile_URL not in all_profile_URL:\n",
    "            all_profile_URL.append(profile_URL)\n",
    "    return all_profile_URL\n",
    "\n",
    "\n",
    "# Task 2.2: Navigate through many page, and extract the profile URLs of each page\n",
    "input_page = int(input('How many pages you want to scrape: '))\n",
    "URLs_all_page = []\n",
    "for page in range(input_page):\n",
    "    URLs_one_page = GetURL()\n",
    "    sleep(2)\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "    sleep(3)\n",
    "    next_button = driver.find_element_by_class_name(\"re__icon-chevron-right--sm\")\n",
    "    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "    URLs_all_page = URLs_all_page + URLs_one_page\n",
    "    sleep(2)\n",
    "print('- Finish Task 3: Scrape the URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Scrape the data, and write the data to a .CSV file\n",
    "with open('output.csv', 'w',  newline = '') as file_output:\n",
    "    headers = ['name', 'address', 'city', 'district', 'project name', 'investor', 'price', 'area (m^2)', \n",
    "               'bedroom', 'post_date', 'expiration_date' ]\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()    \n",
    "    for linkedin_URL in URLs_all_page:\n",
    "        driver.get(linkedin_URL)\n",
    "        print('- Accessing profile: ', linkedin_URL)\n",
    "\n",
    "        page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        info_div = page_source.find('div',{'class':'re__pr-info pr-info'})\n",
    "        dc = page_source.find(\"div\", {\"class\" : \"re__section re__pr-specs js__section\"}).find_all(\"div\", {\"class\" : \"re__list-standard-1line--md\"})\n",
    "        gia = page_source.find('div',{'class':'re__pr-short-info js__pr-short-info'}).find_all(\"div\", {\"class\" : \"re__pr-short-info-item js__pr-short-info-item\"})          \n",
    "        tt = page_source.find('div',{'class':'re__section re__pr-project js__section'}).find_all(\"div\", {\"class\" : \"re__list-standard-1line--md\"})          \n",
    "        ngay = page_source.find('div',{'class':'re__pr-short-info re__pr-config js__pr-config'}).find_all(\"div\", {\"class\" : \"re__pr-short-info-item js__pr-config-item\"})          \n",
    "\n",
    "        try:\n",
    "            name = info_div.find('h1', class_='re__pr-title pr-title').get_text().strip()  \n",
    "            print('--- name is: ', name)       \n",
    "            address = dc[1].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            print('--- address is: ', address)\n",
    "            li = address.split(',')\n",
    "            city = li[-1].strip().strip('.')\n",
    "            district = li[-2].strip()\n",
    "            print('--- city is: ', city)\n",
    "            print('--- district is: ', district)\n",
    "\n",
    "            project_name = tt[0].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            print('--- project name is: ', project_name)\n",
    "            investor = tt[1].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            print('--- investor is: ', investor)\n",
    "\n",
    "            price = gia[0].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            price = price.split(' ')\n",
    "            price = price[0]\n",
    "            print('--- price is : ', price)\n",
    "\n",
    "            area = gia[1].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            area = area.split(' ')\n",
    "            area = area[0]\n",
    "            print('--- area is: ', area)\n",
    "\n",
    "            bedroom = gia[2].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            bedroom = bedroom.split(' ')\n",
    "            bedroom = bedroom[0]\n",
    "            print('--- bedroom is: ', bedroom)\n",
    "\n",
    "            post_date = ngay[0].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            expiration_date = ngay[1].find(\"span\", {\"class\" : \"value\"}).get_text().strip()\n",
    "            print('--- post date is: ', post_date)\n",
    "            print('--- expiration date is: ', expiration_date)\n",
    "            \n",
    "            writer.writerow({headers[0]:name, headers[1]:address, headers[2]:city, headers[3]:district, \n",
    "                             headers[4]:project_name, headers[5]:investor, headers[6]:price, headers[7]:area,\n",
    "                             headers[8]:bedroom, headers[9]:post_date, headers[10]:expiration_date})\n",
    "            print('\\n')\n",
    "        except:\n",
    "            pass\n",
    "print('Mission Completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
